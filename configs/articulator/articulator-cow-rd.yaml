_target_: dos.trainer.Trainer # Class Name

train_dataset:
  _target_: dos.datasets.ImageDataset       # Class Name
  root_dir: /work/oishideb/cow_sd_generated_5  # /0_poses_target_img_NO_KPs.png
  # root_dir: /scratch/shared/beegfs/oishideb/cow  # sample 1
  # root_dir: /work/oishideb/cow_sample_2  # sample 2
  # root_dir: /work/oishideb/cow_dataset/cow_dataset # 9 images
  attributes:
    - name: image
      suffix: _rgb.png
    - name: mask
      suffix: _mask.png
    - name: background
      suffix: _background.png
    - name: camera_matrix
      suffix: _camera.txt

model:
  _target_: dos.models.articulator.Articulator 
  bones_predictor:
    _target_: dos.components.skinning.bones_estimation.BonesEstimator
    num_body_bones: 8
    num_leg_bones: 3
    body_bones_type: z_minmax_y+
    temperature: 0.05

  path_to_save_images: /scratch/shared/nfs2/oishideb/nfs2/dos_output_files/cow/all_iteration_Train/batch_size_0/DOS-2073_Degree_45
  num_pose_for_optim: 1
  num_pose_for_visual: 20
  num_sample_bone_line: 2  # 
  num_sample_farthest_points: 150  # No. of Keypoints to select randomly 
  mode_kps_selection: "kps_fr_sample_farthest_points" # Options are "kps_fr_sample_on_bone_line" OR "kps_fr_sample_farthest_points"
  shape_template_path: /scratch/shared/beegfs/tomj/projects/articulator/data/synth_animals/shape_templates/cow_female-rd/Cow-OBJ-v01/Cow_Highpoly.obj
  enable_texture_predictor: False

  view_option: "multi_view_azimu" # Options are "multi_view_azimu"; "multi_view_rand"; "single_view"
  random_camera_radius: 2.5 # for single_view: 1; for multi-view: 2.5
  fit_shape_template_inside_unit_cube: True # for single_view: False; for multi-view: True
  phi_range_for_optim: [45, 45] # [0, 360]; For one sideview [90,90]
  phi_range_for_visual: [0, 360]
  
  # Options are
  # "rand_phi_each_step_along_azi_for_one_fixed_iter"
  # "rand_phi_each_step_along_azi_long_short_update_intervals"
  # "alternate_2_side_views_each_step_along_azimuth"
  # "alternate_4_side_views_each_step_along_azimuth"
  # "multiple_random_phi_in_batch"      # if selected this, then specify the no. here - "num_pose_for_optim"
  # "2_side_views_only_in_batch"        # if selected this, then specify the no. here - "num_pose_for_optim"
  # "guidance_and_rand_views_in_batch"  # if selected this, then specify the no. here - "num_pose_for_optim" as 2
  multi_view_optimise_option: "rand_phi_each_step_along_azi_for_one_fixed_iter"

  bones_rotations: "bones_rotations" # Options are "bones_rotations"; "DUMMY_bones_rotations"; "NO_bones_rotations"
  using_pil_object: False
  cyc_consi_check_switch: True    # IMPORTANT: THIS SAME VARIABLE IS USED AT TWO PLACES, SWITCH ON/OFF AT BOTH PLACES
  cyc_consi_check_dist_threshold: 30 # 15
  cyc_check_img_save: True # This saves all the images with Cycle Consistency Check
  # seed: 60
  target_image_fixed: False
  save_individual_img: False    # IMPORTANT: THIS SAME VARIABLE IS USED AT TWO PLACES, SWITCH ON/OFF AT BOTH PLACES
  
  correspond:
    _target_: dos.components.fuse.compute_correspond.ComputeCorrespond
    only_dino: True # If TRUE, this will switch off the loading of ODISE model that extracts sd features for the FUSE Model.
    batch_compute: False    # Switch to turn on and off the Batch Computation for the correspondences
    cyc_consi_check_switch: True  # IMPORTANT: THIS SAME VARIABLE IS USED AT TWO PLACES, SWITCH ON/OFF AT BOTH PLACES

  articulation_predictor:
    _target_: dos.predictors.articulation_predictor.ArticulationPredictor  # Class Name
    size_dataset: 49
    num_bones: 20
    degree: 65
    
  renderer:   # variable Name
    _target_: dos.modules.renderer.Renderer # Class Name
    cam_pos_z_offset: 0.0
    fov: 28.84 # blender 70 mm focal length, 36 mm sensor width

  diffusion_Text_to_Target_Img:  # variable Name
    _target_: dos.components.diffusion_model_text_to_image.diffusion_sds.DiffusionForTargetImg # Class Name
    cache_dir: /scratch/shared/nfs2/oishideb/nfs2/.cache/huggingface_hub    # /work/oishideb/cache/huggingface_hub
    output_dir: /scratch/shared/nfs2/oishideb/nfs2/dos_output_files/cow/all_iteration_Train/batch_size_0/DOS-2073_Degree_45/sd_sds_output/
    init_image_path: /users/oishideb/laam/dos/examples/data/cow.png
    vis_name: cow-sds_latent-l2_image-600-lr1e-1.jpg
    prompts_source: '' #.The photo should have a grey background.' 
    # negative_prompts: 'front view, side view, tail, black' #  , cartoon, dead, shadow, reflection'     # the string shouldn't be in a square brackets ['']
    prompts: 'A photograph of a cow running very very fast' # if view_dependent_prompting is True, then 'view' will be automatically specified. 
    view_dependent_prompting: True
    mode: sds_latent # Options are sds_image OR sds_latent-l2_image OR sds_latent
    lr: 0.1  # For DeepFloyd+SDS
    lr_l2: 0.1  # For SD+SDS  1e4
    # seed: 8 # 6
    num_inference_steps: 50
    guidance_scale: 40
    dds: False
    select_diffusion_option: 'sd' # Options are sd, sd_XL, df, sd_dds_loss, mv_dream  # by default is sds loss
    image_fr_path: False
    save_visuals_every_n_iter: 2
    schedule: "[600] * 50"

renderer:   # variable Name
  _target_: dos.modules.renderer.Renderer # Class Name
  cam_pos_z_offset: 0.0
  fov: 28.84

path_to_save_img_per_iteration: /scratch/shared/nfs2/oishideb/nfs2/dos_output_files/cow/all_iteration_Train/batch_size_0/DOS-2073_Degree_45
checkpoint_root_dir: /work/oishideb/articulation_cow_chkpts
experiment_name: articulator-dev-0.1
save_each_iteration: True
evaluate_the_model: False
save_individual_img: False    # IMPORTANT: THIS SAME VARIABLE IS USED AT TWO PLACES, SWITCH ON/OFF AT BOTH PLACES

device: cuda:0

# resume: True

# learning_rate: 1e-9  # tried with 0.01, 0.5, 0.9, 1;   # 1e-4   # DOS_1432
learning_rate: 0.002          
# for debugging
num_iterations: 70
num_vis_iterations: 1
num_eval_iterations: 10
save_checkpoint_freq: 50
num_workers: 0
batch_size: 1
